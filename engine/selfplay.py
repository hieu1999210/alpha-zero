import logging
import os
import threading

import numpy as np
import torch
import torch.multiprocessing as mp

from utils import listener_process

from .selfplay_worker import SelfplayWorker


class Selfplay:

    def __init__(self, game, model, checkpointer, cfg):
        # fmt: off
        self.game               = game
        self.model              = model   
        self.cfg                = cfg
        self.checkpointer       = checkpointer
        self.num_workers        = cfg.SELF_PLAY.NUM_WORKER
        self.game_count         = mp.Value('i', 0)
        self.exp_queue          = mp.Queue()
        self.logging_queue      = mp.Queue()
        self.barrier            = mp.Barrier(self.num_workers+1)
        self.self1_wins_count   = mp.Value("i", 0)
        self.self2_wins_count   = mp.Value("i", 0)
        # fmt: on

        exp_path = os.path.join(cfg.DIRS.EXPERIMENT, "training_data")
        os.makedirs(exp_path, exist_ok=True)
        self.exp_folder = exp_path

    def plays(self, idx):
        """
        init and run selfplay processes
        gather and save training examples
        terminate selfplay processes
        """
        self.model.eval()
        self.model.freeze_param()

        # init and run worker
        self._start_workers()

        # wait all workers
        self.barrier.wait()

        logging.info(
            "player1 vs player2: "
            f"{self.self1_wins_count.value:0>3} - "
            f"{self.self2_wins_count.value:0>3}"
        )

        # collect sample
        self._collect_samples(idx)

        # terminate selfplay process and reset atributes
        self._reset_wokers()

    def _start_workers(self):
        """
        create and start logging thread and selfplay workers
        """

        # create and start logging thread
        self.logging_thread = threading.Thread(
            target=listener_process, args=(self.logging_queue,)
        )
        self.logging_thread.start()

        # create and start selfplay workers
        self.workers = [
            SelfplayWorker(
                pid=i + 1,
                model=self.model,
                game=self.game,
                exp_queue=self.exp_queue,
                logging_queue=self.logging_queue,
                global_games_count=self.game_count,
                barrier=self.barrier,
                cfg=self.cfg,
                p1_wins=self.self1_wins_count,
                p2_wins=self.self2_wins_count,
            )
            for i in range(self.num_workers)
        ]

        for worker in self.workers:
            worker.start()

    def _collect_samples(self, idx):
        """
        collect and save samples generated by selfplaying
        format: {
            "states": torch tensor of shape (N, 1, H, W)
                        where H,W is board size
            "policies": torch tensor of shape (N, V)
                        where V is number of moves
            "values": torch tensor of shape (N,1)
        }
        """

        num_exp = self.exp_queue.qsize()
        logging.info(f"collecting {num_exp} samples")

        x, y = self.game.getBoardSize()
        num_moves = self.game.getActionSize()

        boards = np.zeros((num_exp, x, y))
        policies = np.zeros((num_exp, num_moves))
        values = np.zeros((num_exp, 1))
        for i in range(num_exp):
            board, policy, value = self.exp_queue.get()
            boards[i] = board
            policies[i] = policy
            values[i, 0] = value

        exp_file = os.path.join(
            self.exp_folder, f"iter_{idx:0>3}_{num_exp:0>6}_samples.npy"
        )
        data = {
            "states": boards.astype(np.int8),
            "policies": policies,
            "values": values,
        }

        self.checkpointer.save_data(exp_file, data, iter=idx, epoch=0)

        del boards
        del policies
        del values
        torch.cuda.empty_cache()

    def _reset_wokers(self):
        """
        terminate workers and reset attributes
        """

        # finish workers
        for worker in self.workers:
            worker.join()

        # finish logging thread
        self.logging_queue.put_nowait(None)
        self.logging_thread.join()

        # reset attributes
        self.game_count = mp.Value("i", 0)
        self.self1_wins_count = mp.Value("i", 0)
        self.self2_wins_count = mp.Value("i", 0)
        self.exp_queue = mp.Queue()

        self.barrier = mp.Barrier(self.num_workers + 1)
        self.logging_queue = mp.Queue()
